{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af0d81fa-58be-4dc4-9310-fc107398f70e",
   "metadata": {},
   "source": [
    "One important concept to understand when building chatbots is to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you passing in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9b38d-8300-4eea-ab8f-268d43bb9d6d",
   "metadata": {},
   "source": [
    "## Setup and Important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0104de6f-22a9-4237-9142-e6b8d4f886fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, trim_messages\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages.utils import count_tokens_approximately\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f5e28e1-bf56-46e6-8068-0c7b2c452237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3aaab6-287a-4eaa-8400-fa35ae54d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f21d4590-4b19-4282-ac25-bc2c06391448",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9639c644-5056-40f6-8241-1b9f9127392e",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2696509d-f1d1-477e-96b7-42617ce84cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant. Answer all the questions to the best of your ability in {language}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "178b5d25-6205-4c4e-8f95-a3f102f8b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_message),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e8e863-1a33-4e3a-bd1a-c19e4f52d747",
   "metadata": {},
   "source": [
    "## Trim Messages\n",
    "\n",
    "Helper to reduce how many messages we are sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de9b8024-757a-43f2-a5ab-cf8aa3032a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens=100,\n",
    "    strategy='last',\n",
    "    token_counter=count_tokens_approximately,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91576693-b9f5-4fcc-8fc7-239ee2fe0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content='You are a good assistant'),\n",
    "    HumanMessage(content='Hi I am Saad'),\n",
    "    AIMessage(content='Hi'),\n",
    "    HumanMessage(content='I like to play video games'),\n",
    "    AIMessage(content='That is great to know'),\n",
    "    HumanMessage(content='What is 2 + 2'),\n",
    "    AIMessage(content='The answer is 4'),\n",
    "    HumanMessage(content='Thanks'),\n",
    "    AIMessage(content='No Problems! Anything else?'),\n",
    "    HumanMessage(content='No at the moment, See you next time'),\n",
    "    AIMessage(content='Sure'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b5d5ec-b15b-49c2-92fa-3b2666e0f5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like to play video games', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='That is great to know', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The answer is 4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='No Problems! Anything else?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='No at the moment, See you next time', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Sure', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5018bdd-d42c-4b3a-92b5-b750bccff7e7",
   "metadata": {},
   "source": [
    "## Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3d406cc-9618-4990-bfd2-6d4c26454d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
    "    | prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64788aa5-de6d-4769-bb98-9ecfd9340a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have memory of past conversations.  \\n\\nTo know what you like, you'd have to tell me!  \\n\\nWhat are some things you enjoy? ðŸ˜Š  \\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What do i Like\")],\n",
    "        \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd3dfe3f-8801-4644-b459-647c8c76ffcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"What is 2 + 2?\"  ðŸ˜Š \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71758df9-94e8-43a8-bfec-4e4bb9fc812f",
   "metadata": {},
   "source": [
    "## Wrap in Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2b52349-0cba-46b8-8489-00691997c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "        \n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1647ffeb-f0d2-4cad-9a81-2a0d5127aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\"session_id\": \"chat1\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "929e75ad-4c0d-4475-acc2-b3550a6925fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42c62f36-fd45-4b2e-be9a-68a8031fc076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have access to any personal information about you, including your name.  \\n\\nIf you'd like to tell me your name, I'd be happy to use it! ðŸ˜Š  \\n\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        'messages':[HumanMessage(content=\"What is my name?\")],\n",
    "        'language': 'English'\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf31135-5262-4aa3-b5da-b24cb5e5b836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
