{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac28a385-4534-4f3f-9073-faa6717b659b",
   "metadata": {},
   "source": [
    "## Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc30bd18-6c3d-43f0-afb6-935f3fb11b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cassio\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.schema import Document\n",
    "from typing import Annotated, Literal, List\n",
    "from typing_extensions import TypedDict\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa542f30-850c-46cf-b302-0e382957f7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5278622-a75a-417c-95a3-b38444ce598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"] = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "os.environ[\"ASTRA_DB_ID\"] = os.getenv(\"ASTRA_DB_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33722e1f-735f-4af8-9bd6-28a003bd15d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cassio.init(\n",
    "    token=os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"],\n",
    "    database_id=os.environ[\"ASTRA_DB_ID\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff3bca9-d1b0-4def-8d1f-7dc59281b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model_name=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81488256-9699-45f9-b1a8-8b1dba8adc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd0cde-f61e-43d6-b267-b72d06942ee8",
   "metadata": {},
   "source": [
    "## Wikipedia Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26e5476a-02a8-4acf-9cce-4cffbae902fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=300)\n",
    "wikipedia_tool = WikipediaQueryRun(api_wrapper=wikipedia_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f4d3b06-cbe0-4f3e-9d1b-237cae97d026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Lionel Messi\\nSummary: Lionel Andrés \"Leo\" Messi (Spanish pronunciation: [ljoˈnel anˈdɾes ˈmesi] ; born 24 June 1987) is an Argentine professional footballer who plays as a forward for and captains both Major League Soccer club Inter Miami and the Argentina national team. Widely regarded as one'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_tool.run(\"Tell me about Lionel Messi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01705091-1e81-4519-8e61-b96c637c169e",
   "metadata": {},
   "source": [
    "## Web Base Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf339838-ecf7-4d9a-a406-ffa03350c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6828329-e687-45d1-b8d8-a4ab61f4612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "texts = text_splitter.split_documents(documents=docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c9c8a5e-322d-4989-b928-4d761e6642f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da46b03a-20a7-4249-b75a-8a46f83d9ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d949b4-cc9c-4b4a-a42f-2ddfe86e77ce",
   "metadata": {},
   "source": [
    "## Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d2638ac-8bcd-4ce6-a60a-3108db77e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Cassandra(\n",
    "    embedding=embeddings,\n",
    "    table_name=\"qa_mini_demo\",\n",
    "    session=None,\n",
    "    keyspace=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cb1999f-6cd9-4044-9014-8328ddc839b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 88 headlines\n"
     ]
    }
   ],
   "source": [
    "vector_store.add_documents(documents=texts)\n",
    "print(f\"Inserted {len(texts)} headlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35d95e02-326d-46b8-8c25-2f69a75f43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndexWrapper(vectorstore=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8a61504-4718-48ac-8e19-87bd391dda6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8be74120-f53e-47cf-99d9-f2b39c14fd3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='13063e52b689457ab1a453cdead51b84', metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content=\"Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\\n[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\\nBasic Prompting#\\nZero-shot and few-shot learning are two most basic approaches for prompting the model, pioneered by many LLM papers and commonly used for benchmarking LLM performance.\\nZero-Shot#\\nZero-shot learning is to simply feed the task text to the model and ask for results.\\n(All the sentiment analysis examples are from SST-2)\\nText: i'll bet the video game is a lot more fun than the film.\\nSentiment:\\nFew-shot#\\nFew-shot learning presents a set of high-quality demonstrations, each consisting of both input and desired output, on the target task. As the model first sees good examples, it can better understand human intention and criteria for what kinds of answers are wanted. Therefore, few-shot learning often leads to better performance than zero-shot. However, it comes at the cost of more token consumption and may hit the context length limit when input and output text are long.\\nText: (lawrence bounces) all over the stage, dancing, running, sweating, mopping his face and generally displaying the wacky talent that brought him fame in the first place.\\nSentiment: positive\"),\n",
       " Document(id='1d41e879377e430797e7f41aab320961', metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content=\"Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\\n[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\\nBasic Prompting#\\nZero-shot and few-shot learning are two most basic approaches for prompting the model, pioneered by many LLM papers and commonly used for benchmarking LLM performance.\\nZero-Shot#\\nZero-shot learning is to simply feed the task text to the model and ask for results.\\n(All the sentiment analysis examples are from SST-2)\\nText: i'll bet the video game is a lot more fun than the film.\\nSentiment:\\nFew-shot#\\nFew-shot learning presents a set of high-quality demonstrations, each consisting of both input and desired output, on the target task. As the model first sees good examples, it can better understand human intention and criteria for what kinds of answers are wanted. Therefore, few-shot learning often leads to better performance than zero-shot. However, it comes at the cost of more token consumption and may hit the context length limit when input and output text are long.\\nText: (lawrence bounces) all over the stage, dancing, running, sweating, mopping his face and generally displaying the wacky talent that brought him fame in the first place.\\nSentiment: positive\"),\n",
       " Document(id='98ffd893cc154b85a1376dc397f8b6dc', metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content=\"Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\\n[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\\nBasic Prompting#\\nZero-shot and few-shot learning are two most basic approaches for prompting the model, pioneered by many LLM papers and commonly used for benchmarking LLM performance.\\nZero-Shot#\\nZero-shot learning is to simply feed the task text to the model and ask for results.\\n(All the sentiment analysis examples are from SST-2)\\nText: i'll bet the video game is a lot more fun than the film.\\nSentiment:\\nFew-shot#\\nFew-shot learning presents a set of high-quality demonstrations, each consisting of both input and desired output, on the target task. As the model first sees good examples, it can better understand human intention and criteria for what kinds of answers are wanted. Therefore, few-shot learning often leads to better performance than zero-shot. However, it comes at the cost of more token consumption and may hit the context length limit when input and output text are long.\\nText: (lawrence bounces) all over the stage, dancing, running, sweating, mopping his face and generally displaying the wacky talent that brought him fame in the first place.\\nSentiment: positive\"),\n",
       " Document(id='475bfdf3d1e24895a2b7f80f1760f98c', metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content=\"Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\\n[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\\nBasic Prompting#\\nZero-shot and few-shot learning are two most basic approaches for prompting the model, pioneered by many LLM papers and commonly used for benchmarking LLM performance.\\nZero-Shot#\\nZero-shot learning is to simply feed the task text to the model and ask for results.\\n(All the sentiment analysis examples are from SST-2)\\nText: i'll bet the video game is a lot more fun than the film.\\nSentiment:\\nFew-shot#\\nFew-shot learning presents a set of high-quality demonstrations, each consisting of both input and desired output, on the target task. As the model first sees good examples, it can better understand human intention and criteria for what kinds of answers are wanted. Therefore, few-shot learning often leads to better performance than zero-shot. However, it comes at the cost of more token consumption and may hit the context length limit when input and output text are long.\\nText: (lawrence bounces) all over the stage, dancing, running, sweating, mopping his face and generally displaying the wacky talent that brought him fame in the first place.\\nSentiment: positive\")]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is Prompt Engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4ec548-4be5-4c0d-b2f3-160397a6a96a",
   "metadata": {},
   "source": [
    "## Langgraph Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1b22da5-1386-423d-b533-33752ba3c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouteQuery(BaseModel):\n",
    "    \"\"\" Route a user query to the most relevant datasource \"\"\"\n",
    "    datasource: Literal[\"vector_store\",\"wiki_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user query choose to route it to wikipedia or a vector_store\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e888430-2388-47c1-81b2-c441bbfca14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm_router = llm.with_structured_output(RouteQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10f519cb-0b5d-459d-ae65-6354a4a189b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are an expert at routing a user question to a vectorstore or wikipedia.\n",
    "The vectorstore contains documents related to agents, prompt engineering, and adversarial attacks.\n",
    "Use the vectorstore for questions on these topics. Otherwise, use wiki-search.\"\"\"\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_router = route_prompt | structured_llm_router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab374eb3-770a-4102-8a94-2fca0e593885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='vector_store'\n"
     ]
    }
   ],
   "source": [
    "print(question_router.invoke({\"question\": \"What is Prompt Engineering?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd097814-dd43-411e-8ed7-b343d12ca4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='wiki_search'\n"
     ]
    }
   ],
   "source": [
    "print(question_router.invoke({\"question\": \"Who is Albert Einstien?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9d6d80-ed8f-452e-8a9a-646fe2c13651",
   "metadata": {},
   "source": [
    "## AI Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bc9faae-f911-4dbd-ac13-f7baa74a66fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "    question:str\n",
    "    generation:str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f11b7377-b0df-422c-9139-00cf6b68587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"--- Retrieve ---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\":question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b7e1228-ffa8-4621-88c1-88827ccfd01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_search(state):\n",
    "    \"\"\"\n",
    "    Wiki search based on the re-phrased question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Update documents key with append web results\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"--- Wikipedia ---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    docs = wikipedia_tool.invoke({\"query\", question})\n",
    "    wiki_results = docs\n",
    "    wiki_results = Document(page_content=wiki_results)\n",
    "    return {\"documents\": wiki_results, \"question\":question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6aeb2d66-5f79-491b-87a3-3ef03a8af7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to wiki search or RAG\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"--- ROUTE QUESTION ---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "\n",
    "    if source.datasource == \"wiki_search\":\n",
    "        print(\"---ROUTE QUESTION TO WIKI SEARCH---\")\n",
    "        return \"wiki_search\"\n",
    "    elif source.datasource == \"vector_store\":\n",
    "        print(\"---ROUTE QUESTION TO VECTOR STORE---\")\n",
    "        return \"vector_store\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffc586f-0027-4a6f-9128-532d11e5d11c",
   "metadata": {},
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "339b71cc-5209-4684-a00d-28dc56151c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAAECCAIAAACAEa6JAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcE/f/B/BPBklIIEDYW1kqoEZAFLAIoqJSHDhrcdaqVWtRUutq6+jUUKu1zjpK1bpF5OuqdVRBcSBTAWXIRggre11+f5y/lGKCQQmX8Xn+0Yckd5d3rnnl8/lc7j6HUygUAIKgN8FjXQAE6QcYFQjSCIwKBGkERgWCNAKjAkEagVGBII0QsS5AbzRUinltMkGbXCpGxEIE63LezISEwxNxNDqRRifYOFNIFBzWFek3HPxdpXMlefyyfF5pHr+XL1UiVtDMCQx7kkSsB1EhUfBtTTJBm4zfJmvlSC1tSL39aT4B5lRzAtal6SUYFbWePeZlpDU6e5q6eFN7+9PIpvrdWa1+Liwr4DdWi22cyaGxNnj9fjcYgFFRQciTXz1ST6HiQ2NtzK0MrY+afbMlPa1xxFS7fkPoWNeiT2BUOqp6JrycXBe31IXhYIJ1LVp07yJHLESGT7bFuhC9AaPyH401kjspDROXOGNdSE/Iu9PaUC0eMd0O60L0A4zKv55n8/IyWicZR05QeXdaSwv4ExY5YV2IHoCDu1eaX0ozL3OMKicAgP7DLNz6UO+kNmJdiB6AUQEAAKAAN0+9/PALd6zrwMCgCEsiAV+cxcO6EF0HowIAAOkXGnv50oCx/kY3aITlzdMvsa5C18GoABFf/vRB26BIS6wLwQzZFN8/zOLR381YF6LTYFTA41stw+OM/ShQSIx1RZEAwEM86sGogPyMVtc+1J58xZKSkvfff/8tVly9evX58+e1UBFA25bSfL6WNm4AjD0qtWUihh2JQu3R/fDkyZMeXlETvf1opflwcK+WsUel6pnQJ0Bb53dwudytW7dOmDDhvffeW7RoUUpKCgBgz549GzdurKurCwoKOnr0KADgxIkTy5Yti4iIiI6OXrNmTVVVFbr68ePHo6Ojb968GRwczGazg4KCampqNm/eHBERoY1qPfubtTZItbFlA6Ewbv87WFOSy9PSxhMTE+Pj4+/evVtXV7djx47g4OCcnByFQrF9+/aYmBh0mcePHwcGBu7bt+/Bgwd3795duHDhnDlz0KfOnDkTFha2dOnSS5cuvXjxQiQSBQYGpqSkaKlahUKxb12JkC/X3vb1mqGdC9hV/FYZja6tk9KzsrJmz549dOhQAMCnn346cuRIS8uOx9n69+9/8uRJNzc3IpEIAJBKpStWrGhtbbWwsMDhcCKRaM6cOYMHDwYAiMViLdWpRKMT+a0yCpWk7RfSR0YflTY5la6tncBkMo8cOdLS0hIQEBASEtKvX7/XlyEQCFVVVUlJSfn5+Xz+q1F1U1OThYUF+m8/Pz8tlfc6Gp0gaJNZO8KoqGDsYxUTEp5A1NZPjxs2bJg5c+bdu3dXrlw5atSo3bt3y2SyDsvcunVr5cqVvr6++/fvf/Dgwc6dOzssQCL13AeXRCEg8HixGsbeqhBJOF6LTEsXBtLp9Pnz58+bNy8nJ+fGjRsHDhwwNzePj49vv8y5c+eYTObSpUvRP7lcrjYq0VBro4QGr5FUw9ijgnY5ACB3+5ZbW1svX748YcIECoXCZDKZTGZRUVFhYeHrizk6Oir/vH79erdXojmtdkf1nbF3wGxdKCKhVvocRCJx3759X3zxRU5ODofD+d///ldYWMhkMgEAbm5ujY2NN2/efPHihY+Pz7179x4+fCiTydBjxwCA2tra1zdIJpPt7OyUC3d7wQoEMBxI8Mp7dYw9Kg69KMVZbdrYMo1G27p168uXLz/66KPo6Ojk5OSEhIS4uDgAwLBhw5hMJovFunLlypIlS0JDQ1euXBkSElJXV7dx40ZfX9/ly5dfvnz59W3Onz//wYMHiYmJQqGw2wsuzef18E+x+gVe2gV+ZT3/ZIsXnJbh2p/1Ll7UvoPNsS5ERxn9BwSA/qGWVUUCrKvAnqBN3suXhnUVuguO4YBfCP3KH3Uz+7mpW2DTpk3qRtsymQz96fB1GzZs0NIZKACATrbcSUknT560s1N9DnXOPy1W9iQKDX51qgU7YAAA8NfRere+1D6Bqvsezc3N6sYGYrGYTFZ99IzBYFAolG4t8181NTXqnuqkJHt7ewJB9ah91+cli7730N5PTAYARgWgp7fcON3w/keOGixrgHJvtyIKwAy3wLoQnQYbXAAAoFkQ/YbS0w6oOERr8Mry+ZXFApiTN4JReaW3H83RnXL9pHFdYs6pkdxOaYgx1ua0S2AH7D+eZfOqngkipxrF9cPVJcL01MZpCa5GO/9Gl8BW5T+8mWYMe9K5XdUKPZjq/p08vc/NvNw0bQXMiaZgq6JC1XPhjZMv+w42HzyKgXUt3a+iSJBxodG9Hy0kxhrrWvQJjIpqCgRkXuHk3GoJGsVw9aHauXb/+ZQ9TMSXl+bza8tEvFZZ2PvWNs56/456GIxKZ6RiRc7tlpJcnoAr6xtEBwBQzQnmDBNE/u9Oa25utrKywrTMfwmFQlNTU/TfRCLgtyF8rkzQJm9pkDbWiHr7mfUNojt7aevXHsMGo6IRfqusukTEbZYKuHIAAK9Fhk5L8PDhwwEDBqj7ya/nPXjwwMvLC42uqRlBgSiodCLVnGDrTHHopStF6ikYlbd36dIlNze3nrygVxN79+5dtGgR1lUYIBiVt/Htt9+uW7cO6yo6s2PHjtjY2N69e2NdiOGAB4u77JdffvH19cW6ijeYO3fuqlWrsK7CoMBWpQtu3LgRGRmJzjyEdS2aun//fnBwMNZVGALYqmhqy5Yt6Pm8epQTAIC7u3toaKhy2iTorcFW5c3q6uocHBwePHiATl2ndyQSSUVFha2trX6FXNfAVuUN9u/ff+vWLQCAnuYEnUnMy8tLoVDMnz9fKoWzEr8lGBW15HI5j8dDEGT69OlY19INLC0tExISTp06hXUh+gp2wFS7desWHo8PDQ1Vd9mgXtu2bduKFSuwrkLPwFZFhWfPnqWmpr733nsGmRMAgI+Pz+bNm7GuQs/AVuU/qqur6XR6W1ubs7OB35Wbw+FYW1tnZGSEhoZiXYt+gK3Kv/Ly8pYsWUKj0Qw+JwAAa2tr9ODe+vXrsa5FP8DJjf7V0NCgvTst6qa4uDh7e3sAQGNjo42NDdbl6DTYqoDS0tI5c+YAAEaMGIF1LRgICwsDADx8+HDfvn1Y16LTYFTA0aNHd+/ejXUVGBszZgw6VINjV3WMd1gvk8n+/PPPWbNmYV2IDhGLxc+fP+dwOOHh4VjXonOMt1UZNmwY/EB0QCaT/fz8zp8/n5ubi3UtOscYW5X8/Hx/f3+sq9BppaWlHh4etbW17W+TZOSMq1WRyWRTp041MzPDuhBd5+HhAQBYsmTJ48ePsa5FVxhRq8Ln88vLy6lUKrw2UHOpqanjx4/HugqdYCytytq1a8VisZ+fH8xJl6A5SUhIePbsGda1YMwoovLnn39GREQwGAY4/13P+OGHH3777Tesq8CYgXfATp48OW3aNIlE0pN3fzdg58+fHzdunImJCdaFYMCQW5Xdu3fzeDz02iasazEQwcHB4eHhEokE60IwoLZVaW1t7fFiug2XyzU3N0f/q71XMdrrb7lcLofD6dWrF9aF9Ci1p0vq75WlfD4fh8NJpVIKhaK/70KXmZub83i8qVOnHjlyRHdm1tQ2ta1KY2NjjxfzrhQKBQ6Haz9vr1YZ+am4ZWVlNTU1wcHBRjJ0MZyxikgkEovFAICeyQnUu3fvsLAwBEF0fKLN7mIgUUEQBO1xYV2I0SGTyeHh4cZwarbed8BkMhkAgEAg4HA9ffspI++AtYd2eg37p30MWpXy8vLZs2d3y6ZkMhmXy+0kJ6mpqWw2u1teC+oE2unl8Xjff/891rVoCwYXDBcXF3fXphQKRee3AYKnY/SkmTNnPn36FB3xG94JRBp1wB49erRu3bqkpCTlvUSKioo+++yzTZs2BQcHP3ny5OjRo0VFRRYWFkOGDImPj6dSqehimZmZv/76a2Njo4eHR2xsbHR0dHJy8rFjx9BnFy5cGBcXJxAIfvnll5ycHB6P5+bmFh0dHRsbi+7uTz75ZNOmTT///LOlpeWuXbuU9chkspaWlvb9n8rKyuTk5Ly8PIVC0a9fvylTpvj7+3/++ed5eXnoAjt37vTy8rp79+6RI0cqKyvpdLqnp+fSpUvt7OwAAN988w0ej7e3tz916tT69euHDRvWyZtSgh0wdU6cOFFTU2NgU40RNmzYoPIJgUCg/Le9vX1qaiqJRAoMDEQfuXDhwosXL5YvX15bW5uYmEin0zds2BAeHn7t2rW0tLTo6Gg8Hp+Zmblp06YlS5aMHTuWRqPt2bPH2dl54sSJYrG4sbHxzJkz/fr1AwCsXr26ra2NxWLNnj1bIpHs379/8ODBNjY2fD4/NTW1trZ27NixsbGx7T+XIpGo/c9/Eolk6dKljo6Oy5YtGzVqVEFBwfHjx8ePHz9u3LiHDx8ymcxdu3YxGIysrKwNGzZMnTo1MTGRyWTeuHGjoKAgMjISAJCRkVFWViaVShcuXOjr68vhcNS9qfa76PXwQCh/f/+ysrK+ffvK5XKDmUtNo7EKgUAYPnz4nTt3lI/cuXMnMjKSQCDcuHGDSCR+9dVXrq6u7u7uCQkJJSUlGRkZAIDk5OSwsLARI0YEBgZ+8MEHU6ZMaR8/1P379wsKChISEvr06WNhYTFjxgw/P78jR44AANDhR0BAQFxcXJ8+fdDDXFwu9/XPaFVVVXNz88SJE728vDw8PNauXfvll1/K5fIOr4XWM2nSJAsLC19f34ULF96/fx/tDeJwuPr6+vXr1w8dOtTS0rKTNwVpaObMmUQi8fbt2xcvXsS6lu6h6bA+PDz85cuXz58/R8fl1dXVERERAIAnT56gn3J0MXt7e0dHx/z8fARBysrK0I84asGCBTExMR02W15eTqFQ2p8i4e3t3X6A4e3trfx3a2uryi9yZ2dnS0vLpKSk48ePFxQU4PH4gQMH0mi0Dot1qMfHxwftSaJ/urq6Ko81q3tTGu4rCIXD4aKiojIzM0tKSrCupRtoOqwfMGCAlZXV7du3vby8MjIybGxs0HELj8crLi5G5/tQam5uFolECIK88ayHpqamDj+GmJqaCoVC5Z/tz3RUN4Ink8lbt269fPnyuXPnDh8+7OjoGB8fHxUV1X4ZPp8vFovb14MetFE2dO2fUvemOn8vkEobN27kcDhYV9ENNI0KDocLDw+/e/fuvHnz0tPTlVNmMRgMPz+/Dgd/6XQ6mUzG4/FvvAMOlUoViUTtHxEIBOjEh+0pFAoej9fJuY+urq4ff/zxrFmzsrOzr169unXrVnd3dy8vL+UCaBLavxYaEpUXsah7U52/F0idjIwMW1vboUOHYl3IO+nC7yrDhw+vqKi4f/9+SUmJ8ju7d+/eDQ0N/fv3H/j/LC0tXV1dCQSCj49PQUGBcvVDhw7t3bu3wzZ9fHxEIhHar0MVFRW5u7u//uroSSsqVVZWXrlyBQBAoVCGDh26bt06IpHY4TAxkUj09vZGD2Winjx5gtb/+gbVvSnN9hPUUWFh4YsXL7Cu4l11ISq+vr62trbJycm9e/dWfprj4uIQBNmzZ49IJKqqqjpw4MDixYvLy8sBADExMY8ePTp9+nROTk5aWtrJkyfRMYmzs3NTU1NGRkZVVVVQUJCjo+OOHTuKi4ubmpoOHz5cWFg4efLkDi+Nw+E6aVLa2tq2bdu2f//+6urqqqqqEydOyGQy9M6mTk5OhYWF2dnZzc3N48ePz8jISElJ4XK5OTk5+/btYzKZ7VsepU7eFPQWYmNjQ0JCsK7iXWl0sFiJw+Gkp6dPnDhROTkQmUwePXp0UVHRvn37jhw5IpfLZ82ahd6n09PT09TU9OjRo5cuXXr+/PnMmTPRsx6srKyePXt28uRJOp3OZDKZTGZBQcHBgwfT0tLEYvGSJUvQQ9JcLjc1NTUqKsrJyQltFtS9Bzs7OwaDcf78+RMnTqSmphIIBPSQGnpJSWZmZkpKSkBAQFhYmImJSUpKyu+//56bmztw4MBPP/0UHSmlp6fz+fzo6Og3vqn24MFiDdnY2BjAtT36cQ7YG8cqmIA/QWrowoULxjVWwVYnYxVIxxnGWEU/bhpRUFDw9ddfq3v24MGDBtC+G7DY2FgD6KzqRwcMvWmOuqccHBx6tpZXYAfMqOhHq6JQKGg0mq6NVSANwbFKj4JjFf0Fxyo9p/PfVSAdZ+BjFQRBerwYPdPhnHzIsOnHRKwymWzz5s0bN27EuhDobcCxSs9BEOSvv/7CugroLRnGWEU/WhUEQa5fvz5y5EisC4HeRmFhIZVKdXNzw7qQd6IfUYEgzOlHB0wmk3Xyaz2k4y5cuHDv3j2sq3hX+hEVOFbRa3Cs0nPgWEWvwbEKBBkR/eiAwbGKXoNjlZ4Dxyp6DY5Veg4cq+g1OFaBICOiHx0wOFbRa3Cs0nPgWEWvwbFKz4FjFb0GxyoQZER0+irIJUuWlJeXo5PlcTgcBoOBw+FkMpnB3IfAsKEzJCoUCoFAQCQSyWQy+r184cIFrEt7Gzo9Vvnwww9FIlFNTU1NTY1YLK6tra2pqTGYW9sYPAcHh6qqqtra2tbWVg6HU1NTU11djd5/Sh/pdFTCwsL69u3b/hEEQZQ32YN03AcffNDhPh82Njbz5s3DrqJ3otNRQW/+1H46PCcnpw8++ADTiiBNRUZGdrjRwMCBA2Groi3Dhg1rP1k9egsHTCuCuiA+Pl75Tefo6Dh//nysK3p7uh4VAMCcOXPQ3W1razt9+nSsy4G6ICIiQnmLQr1uUvQjKqGhoeju9vf3HzBgANblQF0zY8YMCwsLBweH+Ph4rGt5J295sFjIkzfWSMTCjnfx1ZL3IxcIGy1Gh8U/z+H1zCtSaAQbJzKFqgdfJQAAmVjRVC/htcgQ3fuVzMUqqJ9bJIPBIIpdeux/n+YIBJw5w4RhT8K/6cBql3+CROSKK3/UV5cIXbypMonO/Y/pNjhQWypw60uLnmWPdSlv8PCv5mfZPBweWNtTxKIe+vIyGKbmhLpyIdmU4DfUvF9wZ7f77FpUJCLkzM7qoFG2Dr0oGiyu9yoK+U/uNU9e5own4LCuRbWMtCaxEAkaDefkf1f/nK7v7U/1HaJ2vt+udTBO/Vw1bKK9keQEAODWl8Ycbn1uVzXWhaj24GqTWKSAOekW4VPsS3J5xVlcdQt0ISpPMrmuPmaWtiQNljUcDr1NLWzJpXlvuKt4zxMLkLICQdCojjcuh95aSKx9XnorUNPN6kJUXlaKqHRjPKmEQiW8rNK5W1Y01UuAjvYK9RXZFN/SIBXwVI/3uhAVsQChWxtXk4KytCWJ+Do3XOa1yKwdjKUn3GPsXE3bODKVT3UhKiKhXC433ENe6slkColI526hgSAKCTze1d2EPBlQ0wPTj98NIAhzMCoQpBEYFQjSCIwKBGkERgWCNAKjAkEagVGBII3AqECQRmBUIEgjMCoQpBEYFQjSiB5EpbT0eWRUUG7uY6wLMXztd/XXG1Ylsj55fRl1j2OuqqoiMirowUNtTbmvKxOxnks5WVhUsOaLja8/ZWlpNXvWAjs7ByzqMi6a7Orw8CipVNKDRekKXYlKUdETdU8xGNbz5i7u2XKMlCa7OmpEdE+Vo1u02AFDW/N79+5MmTZmwcIP0DsK7d23Y95H02Jiw79Ys/zevTvokgkrF165mnb16v8io4KKnxWeOXt88tToO+k3o0YF//Iru0MH7PKVC0uWzR0bM2zJsrmnzxxD5wb47cCvMbHhUqlU+erHTySPih4qEAjUrWJsdv6atDLx3xjMmTdlwqQo5Z+bv1m7eu1n6vq6HE7j1Oljv96wSqFQaNgBu5eZvmLlorExwz6cNfH7H7/mcBrRx5uaON98u27GzPcnxo389vsvKyv/ve/K2XMnVn2xLHZ8xOSp0Zs2r6muqUIf7/B5AAC0cdu2sjdHRgVNjBv5zbfr6uvr2r900k/fRkYFTZk2ZscvW952b6mgxaiYmJgAAJKP/DZ92qzElesBADt+2XL6zLFJE6cfO3pheHjU1xtX3frnbwDAzz/t69fPf/TomBt/P/Tx7ksikQQCfmrq6TWrN02aMK39Nq/9ffnHLRt9vPseO5K64KOlp88c27krCQAQGTFaIBDcv5+hXPL2nRshQ9+jUqnqVjE2/v4Dnxbmy+VyAEBzc1N9fS3av0efzcvPDgoconJFoVC4avUya4bNurXf4HAaXXhZ/KxwzdrPBg0afPjg6eWfriopKf5xywYAgFwuX5G4KDvn0YqEtQd/O2FlyViydA4aiby87F92bvXzG7hpE3v1Fxubm5u+/W49urUOnweZTLZ6zfJGTsNPSXs+Xfb5y4b61WuXy2Svrsc6dHjPgAEBPyXtmTY1/lzKyes3rnbT/tNmBwzdrYODhk6d8iEAQCwWX7maNvODueNjJwMAxo2dkJ+fk/zH/uHhUa+vKBKJZsyYEzBoMNo6KZ+6eDFlwIBBCZ+tBgBYWTHmzVm8hb0pfuZ8T09vJyeX23duhIUNR78FnzzJ+/qrH9StMmf2Qrp5ZzPZGB5/v4Eikai07Lm3V5/snEceHt5mNLOc3CwXF7e6utqGhpeBAUNeb2/lcvmXXyUK+Pzdu5JJJE2vgc3Py6ZQKPEfzsfj8fb2Dn37+JaWPUfzUFFRnsTejf6f/WRxQnrGrTNnji3/dJWvb/9DB066uLih9wiRSaVr169obWu1oFt0+DzcSb/59Gn+74dOu7n1AgC4urqfPHWkqYmDvvQgZtCokWPRf5w9dzwv7/GIyNHdsgO1fgTMx/vV3JvFxU8lEsngoBDlU8yBgaWlz1vbWlWu2LdPxxnvEQTJL8hpv4VBgwYjCJKb9xgAMGrk2Nt3rqPfmv/cvm5qajosLELdKiUlxd39RnWdjY2tk5NLXl422ob4+w3s18+/oCAXAJCbm2VtbdO7t2f75XE4HA6H28LeVFhUsOXHnZaWVuq33ZF/f6ZIJFqzLuHU6aNV1ZUWFpaDmEHo65qYmKCfePQlmAMDc3KzAAAEAqGmpmrN2s/eHz88Mipo7foVAICW5iblNpWfh5KSZ1QqFc0JAMDHu+/6td/Y2b2arq2/P1O5igXdUizutkkRtD6sJ5HJ6D94PC4A4NPPPuqwQHMTx4JuoWLF177DJBKJVCo9cHDXgYO7/rOF5iYAwMiosb8n7896/GBw0NA7d268994IIpEoEolUrtKmJp+GLWDQ4IKCnLhJ03NyHs2bu5hMpmzf8SMAIDfv8aD///gqKRSKnNwsmUxmbmZOJnftIn4f774/fL/jn3/+3rf/l127twUGBM+ds8jffyCPx5VKpZFRQe0XRkOYnn5r/VeJH86ct2jhZ56e3g8fZa76Yln7xZSfBz6f10k9BKK2PtI9dwTM2sYWAJC4cp2zs2v7xzU/CkyhUKhU6uhRMeH/7bM5OboAAFxc3Dw9vdPTb/r49MvOefTD9zs6WcXdrfdrmzd8gYFD9u7d3traUlr6PGBQMPpF3trakpefPXPG3NeXp9HMNnz1Y9K2b3/48esk9m4NByqoIcGhQ4JD581d/OhR5pmzf65dl3D2zF/W1jampqbffrOt/ZIEPAEAkHbxXP/+zAUfLUUfRL9YVaJSaUKhAEEQPL5HfxXsuai4OLuRyWS0E4k+0tzcpFAoqFSq5hvx9PTh8rjKLUil0traamXjGxkxOi3trLu7B51uoWzlVa5iZcXo1jenHwYxg+rqa/++fsXT0xvd7X36+F67dqmiojwoaOjry3t6eDOZgRu/3rLok/ijxw7Ff6jpLR+ysx+JJeIhwaE2NrbR0e87ODglrFxYV1/r6ekjFArt7BycnVzQJWtqqy0trNB23sHeUbmF27evq9t43z6+IpGoqPhpv75+AICKivKffv7u06Wfk/+//6IlPZdLKpU6d86i5D/25+VlSySSW//8zVq15OftP6DPOju7Pn2an/X4QXO77unrPv5oWXr6zYuXziMIkpeXvWnzmpWsxRLJq1/EIiJG1dXXXr6cGhk5WnkfPJWrKA+YGBULC0sf775nzhzz93t1jxp/v4Fnzx338PCytlY7RaWHh9fHC5Yd/n1v8bNCDV8ovyBnw8ZVF9LOtrQ0P3maf/bccRsbWwd7x8CA4ODgUDZ7c319XWtrS8r5U4s/mXX5cioAwMvT58HDe4+zH8pkslOnj6LbqauvfX3jQUFDnZ1d9+3bcfvOjQcP7/28/YeGl/Xu7lrvJvRoEzZj+uzPWV8dO344dkLE9h0/Ojm6JCa+OiAYGxOHw+E+X7W0pPRZJ1vo35+5b8/R3NzHkyaPYq1awufzvtn8k/LrxNnJpY9Pv+JnhVGR0Z2vgh7INkKDBg2uqa3u338Q+qef34Ca2upBzI4DlQ6mTY1nDgzcsGGVUCjU5FWmTY2PGTdp56/sSZNHrVi5kEqlbftpH3po6/tvfx4+fOSmb9ZMjBt59tzxkSPHxsXNAADMn79kSHDo+i9Xjh4TUl9ft/qLjX37+K5es/za35c7bJxIJLK37EIUyFdff77qi2UUU9Pvv9tO1NoQRakL03uf31vjE2jp4t2F/pJhKMnlvnwhGB2vW1PiFz3iluYJhk3Srar03aWDVeGTbFTOyq0Hp0tCkC7QlXPAIP1y7M/Df/55WOVT7r08du442OMVaR2MCvQ2YmMnR6r5FZxIMMwPlWG+K0jbzM3Mzc3U3rXHIMGxCgRpBEYFgjQCowJBGoFRgSCNwKhAkEZgVCBIIzAqEKQRGBUI0giMCgRppAtRoTNMcEaZLDweR7PQudMaTEgEMpWAdRWGxszShGCi+mLPLnz2qeaEhkpR91WlN15WCOlWOhcVhoNJ1TM+1lUYmtI8rq2T6qspuxCVXr60No4xzsDJa5G69aVhXUVHlrYmFjYm/FZjvJxTS+pfiPoG0YHxooq4AAAMcUlEQVSaGQS6EBV7N7JjL0r6+ZfdVpo+uHmqzmeQmYWNzrUqAIDhcbbXj6u4pBZ6C0Ke/J+zdSOm26pboAtXQaJy/mmtKBI4e9FsnCnqenUGQCpWNFYLS3O5zOGWPgFmWJejVluTLPmb8pAYO3OGiZmViXHOMfsucDhca4OE3yrN+adp1lp3EkVt49HlqAAAqkuEhQ+4Aq685WUP9ccUCsDlcun0njvrm25tQrcm+odY2rpoOqUihu5fbqopE0olChFPjnUtKohEIjwer/nklD3JwoaEwyucPagBUZadL/k2Uel5EokkIiIiIyNDg2UhnbN161Y3N7fp06djXcg7McqjvxDUdTAqEKQRGBUI0giMCgRpBEYFgjQCowJBGoFRgSCNwKhAkEZgVCBIIzAqEKQRGBUI0giMCgRpBEYFgjQCowJBGoFRgSCNwKhAkEZgVCBIIzAqEKQRGBUI0giMCgRpBEYFgjQCowJBGtGbqOjFJEyQAdOPqBCJxMjIyG3btmFdCNRl165dS09PHzp0KNaFvCv9iAoej//uu+/s7e2Dg4NPnjyJdTmQRp4+fbpgwYJr164dOHDA3d0d63LelX7MLqmEIEhSUlJGRgaLxQoLC8O6HEi1tra2pKSk0tJSFos1cOBArMvpHnoWFVRlZSWbzUYQhMViGcDXlYHZt2/f8ePHWSzWuHHjsK6lO+llVFB3795NSkoKCgpisVhEoi7e1MHYXLx4kc1mz5gxY+HChVjX0v30Y6yiUkhIyOnTp728vIYNG/bHH39gXY5Ry8nJmTVrVmZmZkpKikHmRL9blfa2b99+9erVxMTEESNGYF2LceFwOFu3bm1sbExMTOzXrx/W5WiRgUQFAFBfX5+UlNTS0pKYmNinTx+syzEKO3fuTEtLY7FYI0eOxLoWrTOcqKCysrKSkpJ8fHxYLBaNpnM3cDQY586dS0pKWrBgwdy5c7GupYfo8VhFpYCAgKNHjwYEBMTExPz2229Yl2OA7t+/P3369CdPnvz999/GkxMDbFXa27Nnz+nTp1ks1pgxY7CuxRDU1NSw2WyRSJSYmOjp6Yl1OT3NkKMCAGhpaWGz2VVVVYmJif3798e6HD32008/3bx5k8VihYeHY10LNgw8KqiCggI2m+3k5JSYmMhgMLAuR8+cOHGCzWavWLFi5syZWNeCJUMbq6jk5+d36NCh4cOHz5gxY9euXViXozfu3LkzceLEioqK+/fvG3lOjKVVae/gwYOHDh1isVgTJkzAuhbdVV5evnXrVhMTExaL5eLignU5OsHoogIAEAqFbDa7oKCAxWIFBQVhXY5ukUqlbDb70aNHn3/++ZAhQ7AuR4cYY1RQz58/Z7PZZmZmLBbLwcEB63J0QnJy8u7du1ks1uTJk7GuRecYb1RQN2/eZLPZUVFRK1aswLoWLF2/fp3NZo8ZM2b58uVY16KjjGJY34mIiIi0tDQ7O7shQ4a8ftHYqFGjTp8+jVFpWhEdHd3hkaKioo8//vjKlSuHDx+GOemEsbcqSnK5PCkp6d69eywWKzQ0FH0wICDA0dHx4MGD9vb2WBfYDb788stLly7Z2tpeunQJAMDn89lsdnFxMYvFGjRoENbV6ToYlf+oqKhISkpCLxqbPXs2n88HAAQHBxvAIea0tLSkpCQul4sgSFZW1m+//XbkyJHExMTY2FisS9MPMCoqoBeNlZaW4vF4AACJREpISJg2bRrWdb09LpcbHx9fXV2N/okgyMKFCxcvXox1XfoERkW1kJAQqVSq/NPR0XH//v36e6CMxWJdv34dTT4alaysLKyL0jPGPqxXKTY2tn1OAADV1dUbNmzArqJ3kpqampmZqcwJOgMOnMSjq2CrokJgYKByt+BwOBwOp1AoiETixx9/vGDBAgCAAgF8rlwuRbCuVA0cjmpGMCHjAACNjY0zZsxoamrC4XAIguBwOHQRhULh4OCAju8hTcCoqHbq1Km2tjY+ny8SiSQSiUAgkPKoE0cteVkleVkhkIoRmhVJLtHRXUezJDXXCwAAdAbZyt7kxv0/iBZNFAqJQCDQaDRzc3NTU1MKhTJlyhSsK9UnMCpvlp/RVviQy2tDqFZUCzsakUQgkPSg44rIFXKJnN8s4jfxW+oE/YItQt+3ptD0oHLdBKPSmdJc/q1zDVQrU2t3BlEf4tGJ1jpeXTHHdyj9vQk2WNeil2BU1PrreGNbk8LcgU4yNZxJxpoqWlvruDNYbqY0HNa16BkYFdVO76jGk00ZbhZYF9L9JEJZyb2qGSxXKzsS1rXoExiVjhQKcH5vPY5sauFgyBO+VGTXjpllZ+cC06Ip/e5/a0PagTqDzwkAwI3peHp7pVRXD+LpIBiV/7h3uVkkJhp8TlBeIS7HtlRiXYXegFH5VxtHmp/eauthhXUhPYRkSqQyaP+kcLAuRD/AqPzr1tlGW0/jms/Ftrflk7utEpGunnagS2BUXnlZIW5tQizsjaLr1Z5DH+v0NNiwvBmMyiu56a1Uhu7mJDvvGuvLITx+c7dv2dLRrCCjtds3a3hgVF4pK+DTbalYV4ENK0dqWQEf6yp0HYwKAAC8rBSTKEQimYB1IdigWlGf5/CwrkLXGc4pG++ivkJEs6Job/sPstLuPjhXW//c0d6L2X/keyEz0JPh/zixFgBcwMAxJ85uEosF7q79Y6KXubv6o2ulXf7lYc5FMok6aEC0nY2b9sqjWVKaKmBU3gC2KgAAwGuWKXDa2hVZOVdOnNvs4tRn7cpzY0d98k/G8fMXt6FP4fHEF5V5j7Ivfbb48Hdf3SKakI6f3YQ+lXH/TMb903Exn3+26JC1ldNfNw5oqTwAAIFEaGmQaG/7hgFGBQAA2pplRLK2Gtj7j857uA+Ki11lbsbw9giKjlqYnnmKy2tCnxWLBdMnrbdmOBMIxIAB0Q2NL8RiAQDgzt2TA/yiBviPoFLpgwPe9/LQ4iyYBBO8TIIgcu29giGAUQEAABwBb0LRSlQQBCmryPXx/ndGU2+PIIUCKSvPRv+0s+1FJr86nEChmAMABMI2hULR2FRpb9dbuZaLU19tlKdk40IV8mVafQl9B8cqAAAAFAqpUApA9w9XZDKJXC69fG3P5Wt72j/O5b9qVXCqOn4iMR9B5MoIAQBIJNNur629hkoB1Rx+GDoD9w4AAJhbElpatNL/IJEoZBI1kDlugN9/bn1szXDuZC0KmYbHE6RSkfIRsUSgjfJQMglCouBx8AKWTsGoAAAAnWGCK9fWuNbJ0Uco4np5BKJ/ymRSTnO1pUVn01XicDgrS8fyirzh/z+tytOidC2VBwCQSxFrJy0eADQMcKwCAAAOvSjcRm19bY8b9Un+01uZj1IRBCl7kX3k5Lq9h5bKZG9I5kD/kXlPbmTnXQMAXL+d/KIqX0vlAQB4HAHD3kR72zcMMCoAAGDtSAIKRCLUyri2tztzxSfJZeXZG34cs/fwp0IRb96HW01MyJ2vNXL4vCGBE1IuJrG+HPK0KH382AR0RiJtVChoFngNNNPGlg0JvArylZtnGjiNRGs3OtaF9DQFoij858UnPxrdHYO7CrYqrzDDLVtq2rCuAgOcyjb/EAOcQqDbwWH9K5a2Jq4+lOZqrpWzucoF8p/eUv6U3gHVlC4Qqo7ZkMAJsWO67aYlZS+yDxxJVPkUgshxODxO1WGsYUOmjRm5SN0264qbpiz26q4KDRjsgP1LxEeO/FjhFeKq8lmpVCwUclU/JZOYEFXP52BCophSunMY0NbW2NVVSCRTCkX19QUNZc0efYiBUZbdUZqBg1H5j/y7bfmZQoc+RjGpnKBF3Frd9AEL3kBYI3Cs8h/+IXQ7Z3xTpeFf6oTIFS8e18KcaA62KircTmmqrwU2vQx2sCuXIXVP6ycvc6JQ4XelpuCeUuG9iQxzM+nLEsO84lzQInqWXglz0lWwVVEr63rL83wR1drMjKHdUxV7jEKuaChtBnLJtBWdnYEGqQSj0pm6MtHNcxyxGNh5MEzpejxnqUwib67iNpS3hMRYD4qAx7veBozKm5U/4efeaat7ITK3pZrbmhFN8EQygUjS6QvxEblCJpbJJAi/WchvEkiFsv5hlkPHGctsgNoAo6IpAVdels+vKRPXvxAKeXI8AScV6eh1g5YOlOZ6kSmNaGlHsnMmeQ40s3d7wyln0BvBqLwtBEilurrrcMCEBK8+6WYwKhCkEXi4EII0AqMCQRqBUYEgjcCoQJBGYFQgSCMwKhCkkf8DKy/oav8bsXEAAAAASUVORK5CYII=",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001DC0C4D6A90>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "wiki_search_node = RunnableLambda(lambda x: wikipedia_tool.invoke({\"query\": x[\"question\"]}))\n",
    "\n",
    "## Define Nodes\n",
    "workflow.add_node(\"wiki_search\", wiki_search_node)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "\n",
    "## Build Graph\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    route_question,\n",
    "    {\n",
    "        \"wiki_search\": \"wiki_search\",\n",
    "        \"vector_store\": \"retrieve\"\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"retrieve\", END)\n",
    "workflow.add_edge(\"wiki_search\", END)\n",
    "\n",
    "## Compile\n",
    "app = workflow.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bd189e7-470a-4898-88e5-444ee3855505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ROUTE QUESTION ---\n",
      "---ROUTE QUESTION TO VECTOR STORE---\n",
      "--- Retrieve ---\n",
      "\"Node 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "('Building agents with LLM (large language model) as its core controller is a '\n",
      " 'cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer '\n",
      " 'and BabyAGI, serve as inspiring examples. The potentiality of LLM extends '\n",
      " 'beyond generating well-written copies, stories, essays and programs; it can '\n",
      " 'be framed as a powerful general problem solver.\\n'\n",
      " 'Agent System Overview\\n'\n",
      " 'In a LLM-powered autonomous agent system, LLM functions as the agent’s '\n",
      " 'brain, complemented by several key components:\\n'\n",
      " '\\n'\n",
      " 'Planning\\n'\n",
      " '\\n'\n",
      " 'Subgoal and decomposition: The agent breaks down large tasks into smaller, '\n",
      " 'manageable subgoals, enabling efficient handling of complex tasks.\\n'\n",
      " 'Reflection and refinement: The agent can do self-criticism and '\n",
      " 'self-reflection over past actions, learn from mistakes and refine them for '\n",
      " 'future steps, thereby improving the quality of final results.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Memory\\n'\n",
      " '\\n'\n",
      " 'Short-term memory: I would consider all the in-context learning (See Prompt '\n",
      " 'Engineering) as utilizing short-term memory of the model to learn.\\n'\n",
      " 'Long-term memory: This provides the agent with the capability to retain and '\n",
      " 'recall (infinite) information over extended periods, often by leveraging an '\n",
      " 'external vector store and fast retrieval.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Tool use\\n'\n",
      " '\\n'\n",
      " 'The agent learns to call external APIs for extra information that is missing '\n",
      " 'from the model weights (often hard to change after pre-training), including '\n",
      " 'current information, code execution capability, access to proprietary '\n",
      " 'information sources and more.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\t\\n'\n",
      " '\\tOverview of a LLM-powered autonomous agent system.\\n'\n",
      " '\\n'\n",
      " 'Component One: Planning\\n'\n",
      " 'A complicated task usually involves many steps. An agent needs to know what '\n",
      " 'they are and plan ahead.')\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"question\": \"What is agent?\"\n",
    "}\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value['documents'][0].model_dump()['metadata']['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dfa64d11-0a74-4e44-80db-cab422cd2923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ROUTE QUESTION ---\n",
      "---ROUTE QUESTION TO WIKI SEARCH---\n"
     ]
    },
    {
     "ename": "InvalidUpdateError",
     "evalue": "Expected dict, got Page: Lionel Messi\nSummary: Lionel Andrés \"Leo\" Messi (Spanish pronunciation: [ljoˈnel anˈdɾes ˈmesi] ; born 24 June 1987) is an Argentine professional footballer who plays as a forward for and captains both Major League Soccer club Inter Miami and the Argentina national team. Widely regarded as one\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidUpdateError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLionel Messi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m }\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mstream(inputs):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# Node\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         pprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\generative_ai_env\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2527\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2525\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2526\u001b[0m             loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2527\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2528\u001b[0m             [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2529\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2530\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2531\u001b[0m             schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2532\u001b[0m         ):\n\u001b[0;32m   2533\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2534\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   2535\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\generative_ai_env\\Lib\\site-packages\\langgraph\\pregel\\runner.py:157\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    155\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     run_with_retry(\n\u001b[0;32m    158\u001b[0m         t,\n\u001b[0;32m    159\u001b[0m         retry_policy,\n\u001b[0;32m    160\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    161\u001b[0m             CONFIG_KEY_CALL: partial(\n\u001b[0;32m    162\u001b[0m                 _call,\n\u001b[0;32m    163\u001b[0m                 weakref\u001b[38;5;241m.\u001b[39mref(t),\n\u001b[0;32m    164\u001b[0m                 retry\u001b[38;5;241m=\u001b[39mretry_policy,\n\u001b[0;32m    165\u001b[0m                 futures\u001b[38;5;241m=\u001b[39mweakref\u001b[38;5;241m.\u001b[39mref(futures),\n\u001b[0;32m    166\u001b[0m                 schedule_task\u001b[38;5;241m=\u001b[39mschedule_task,\n\u001b[0;32m    167\u001b[0m                 submit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[0;32m    168\u001b[0m                 reraise\u001b[38;5;241m=\u001b[39mreraise,\n\u001b[0;32m    169\u001b[0m             ),\n\u001b[0;32m    170\u001b[0m         },\n\u001b[0;32m    171\u001b[0m     )\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\generative_ai_env\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39minvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\generative_ai_env\\Lib\\site-packages\\langgraph\\utils\\runnable.py:625\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    624\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 625\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n\u001b[0;32m    626\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\generative_ai_env\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\generative_ai_env\\Lib\\site-packages\\langgraph\\pregel\\write.py:99\u001b[0m, in \u001b[0;36mChannelWrite._write\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_write\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Any, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     writes \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m         ChannelWriteEntry(write\u001b[38;5;241m.\u001b[39mchannel, \u001b[38;5;28minput\u001b[39m, write\u001b[38;5;241m.\u001b[39mskip_none, write\u001b[38;5;241m.\u001b[39mmapper)\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(write, ChannelWriteEntry) \u001b[38;5;129;01mand\u001b[39;00m write\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m PASSTHROUGH\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m write \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrites\n\u001b[0;32m     98\u001b[0m     ]\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_write(\n\u001b[0;32m    100\u001b[0m         config,\n\u001b[0;32m    101\u001b[0m         writes,\n\u001b[0;32m    102\u001b[0m     )\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\generative_ai_env\\Lib\\site-packages\\langgraph\\pregel\\write.py:142\u001b[0m, in \u001b[0;36mChannelWrite.do_write\u001b[1;34m(config, writes, allow_passthrough, require_at_least_one_of)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# if we want to persist writes found before hitting a ParentCommand\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# can move this to a finally block\u001b[39;00m\n\u001b[0;32m    141\u001b[0m write: TYPE_SEND \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_SEND]\n\u001b[1;32m--> 142\u001b[0m write(_assemble_writes(writes))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\generative_ai_env\\Lib\\site-packages\\langgraph\\pregel\\write.py:199\u001b[0m, in \u001b[0;36m_assemble_writes\u001b[1;34m(writes)\u001b[0m\n\u001b[0;32m    197\u001b[0m     tuples\u001b[38;5;241m.\u001b[39mappend((TASKS, w))\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, ChannelWriteTupleEntry):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ww \u001b[38;5;241m:=\u001b[39m w\u001b[38;5;241m.\u001b[39mmapper(w\u001b[38;5;241m.\u001b[39mvalue):\n\u001b[0;32m    200\u001b[0m         tuples\u001b[38;5;241m.\u001b[39mextend(ww)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, ChannelWriteEntry):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\generative_ai_env\\Lib\\site-packages\\langgraph\\graph\\state.py:770\u001b[0m, in \u001b[0;36mCompiledStateGraph.attach_node.<locals>._get_updates\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    766\u001b[0m     msg \u001b[38;5;241m=\u001b[39m create_error_message(\n\u001b[0;32m    767\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected dict, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    768\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mINVALID_GRAPH_NODE_RETURN_VALUE,\n\u001b[0;32m    769\u001b[0m     )\n\u001b[1;32m--> 770\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(msg)\n",
      "\u001b[1;31mInvalidUpdateError\u001b[0m: Expected dict, got Page: Lionel Messi\nSummary: Lionel Andrés \"Leo\" Messi (Spanish pronunciation: [ljoˈnel anˈdɾes ˈmesi] ; born 24 June 1987) is an Argentine professional footballer who plays as a forward for and captains both Major League Soccer club Inter Miami and the Argentina national team. Widely regarded as one\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE",
      "\u001b[0mDuring task with name 'wiki_search' and id '9d5309a0-8ba2-28ce-140a-c6cff003905c'"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"question\": \"Lionel Messi\"\n",
    "}\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value['documents'][0].model_dump()['metadata']['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f7cdd0-7b20-485e-8b39-73ce7249b25f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
