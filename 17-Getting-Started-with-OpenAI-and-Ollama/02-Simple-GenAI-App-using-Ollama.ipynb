{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192d790a-57e1-4011-b064-42857c442a51",
   "metadata": {},
   "source": [
    "## Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08f6dc4e-e20f-40fe-ac5c-779ecb40dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e2e4ec-13b3-4e95-a667-c2dd5a1fb2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b47f73bf-84d2-4065-baa5-341ec1697627",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61301003-2129-402e-bc73-67f3298588eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OllamaLLM(model='gemma:2b')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OllamaLLM(model=\"gemma:2b\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d2fda7-87c0-4d2a-ab90-7613b9e00e89",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d89a29-133d-4aa8-bc54-15c3c81ffbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant. Please respond to the question asked'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Question: {question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Please respond to the question asked\"),\n",
    "        (\"user\",\"Question: {question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7eb885-f38d-4bdc-b731-2a6a910cee08",
   "metadata": {},
   "source": [
    "## Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6770200b-ca5b-482d-81aa-bd4eb0be7740",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c36862-e937-4eac-8077-6e5c45d278ca",
   "metadata": {},
   "source": [
    "## Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0afb899e-9e09-49c5-8603-5d9c2aa023de",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca52e38-e87e-472f-8b08-2f040c5bcac0",
   "metadata": {},
   "source": [
    "## Getting Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76a0f4fd-f961-4ace-b25e-79a3d72384eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"What is Generative AI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e617810-8158-4f4b-9e97-0189c87b76b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, here is a comprehensive answer to your question:\\n\\n**Generative AI**\\n\\n**Definition:**\\n\\nGenerative AI is a type of artificial intelligence (AI) that focuses on creating new, realistic, and meaningful content, such as text, images, audio, and videos. These models use algorithms to learn from vast amounts of data and generate new content that resembles what already exists.\\n\\n**Key Characteristics:**\\n\\n* **Creativity:** Generative AI models can generate novel and unique content that is not present in the training data.\\n* **Self-supervised learning:** Some generative AI models can learn from unlabeled data, which allows them to generate content without the need for explicit human input.\\n* **Data-driven approach:** Generative AI models rely heavily on large datasets for training, enabling them to continuously improve and generate high-quality content.\\n* **Multimodal applications:** Generative AI models can generate content in multiple formats, including text, images, audio, and video.\\n\\n**How Generative AI Works:**\\n\\nGenerative AI models typically follow these steps:\\n\\n1. **Data preparation:** The model is trained on a massive dataset of existing content.\\n2. **Model architecture:** The model is designed with specific layers and connections that learn complex relationships between input and output data.\\n3. **Training:** The model iterates through the training data, using algorithms to adjust its internal parameters to minimize the difference between the generated content and the original data.\\n4. **Output generation:** Once trained, the model is ready to generate new content. It receives a prompt or input, and uses its learned patterns to generate a corresponding output.\\n\\n**Examples of Generative AI Models:**\\n\\n* **Chatbots:** AI chatbots that can engage in natural language conversations.\\n* **Image generators:** Models that create new images based on specific prompts.\\n* **Text generators:** Models that generate high-quality text documents.\\n* **Audio generators:** Models that create new audio content, such as music and speech.\\n* **Video generators:** Models that create new videos with realistic footage and special effects.\\n\\n**Applications of Generative AI:**\\n\\nGenerative AI has numerous applications across various industries, including:\\n\\n* **Content creation:** Creating movies, music, and games.\\n* **Marketing and advertising:** Generating personalized ads and content.\\n* **Customer service:** Providing automated customer support and responses.\\n* **Language translation:** Translating text between different languages.\\n* **Drug discovery:** Identifying potential drug candidates and designing new therapies.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": input_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a0b1a-692d-4067-a02a-8a882d3ec62e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
